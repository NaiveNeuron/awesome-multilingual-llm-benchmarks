# awesome-multilingual-llm-benchmarks
A curated list of multilingual and/or non-English benchmarks for Large Language Models (LLMs) or NLP models and tools in general.


### Language-specific Benchmarks

|Language|Date|Title|Tasks|Links|
|:---:|:---:|:---:|:---:|:---:|
|Basque ðŸ‡ªðŸ‡¸ðŸ‡«ðŸ‡·|2022-06|[BasqueGLUE: A Natural Language Understanding Benchmark for Basque](https://aclanthology.org/2022.lrec-1.172)|NER, Intent Classification, Slot Filling, Topic Classification, Sentiment Analysis, Stance Detection, QA/NLI, WiC, Coreference Resolution|[[paper]](https://aclanthology.org/2022.lrec-1.172) [[data]](https://huggingface.co/datasets/orai-nlp/basqueGLUE)|
|Bulgarian ðŸ‡§ðŸ‡¬|2023-07|[bgGLUE: A Bulgarian General Language Understanding Evaluation Benchmark](https://aclanthology.org/2023.acl-long.487/)|NER, POS Tagging, Sentiment, Check-Worthiness, Humor Detection, NLI, Multi-Choice QA, Factuality Classification|[[paper]](https://aclanthology.org/2023.acl-long.487/) [[code]](https://github.com/bgGLUE/bgglue) [[data]](https://huggingface.co/datasets/bgglue/bgglue)|
|Cantonese ðŸ‡­ðŸ‡°ðŸ‡¨ðŸ‡³|2024-08|[How Far Can Cantonese NLP Go? Benchmarking Cantonese Capabilities of Large Language Models](https://arxiv.org/abs/2408.16756)|Yue-TruthfulQA, Yue-GSM8K, Yue-ARC-C, Yue-MMLU, Yue-TRANS|[[paper]](https://arxiv.org/abs/2408.16756)|
|Catalan ðŸ‡ªðŸ‡¸|2021-12|[The Catalan Language CLUB](https://arxiv.org/abs/2112.01894)|NER, POS Tagging, NLI, Document Classification, QA, STS|[[paper]](https://arxiv.org/abs/2112.01894) [[data]](https://huggingface.co/BSC-LT)|
|Chinese ðŸ‡¨ðŸ‡³|2024-09|[CJEval: A Benchmark for Assessing Large Language Models Using Chinese Junior High School Exam Data](https://arxiv.org/abs/2409.16202)|Multi-Choice QA, Bool QA, Fill-in-the Blank QA, Analysis QA|[[paper]](https://arxiv.org/abs/2409.16202)|
|Chinese ðŸ‡¨ðŸ‡³|2020-04|[CLUE: A Chinese Language Understanding Evaluation Benchmark](https://www.aclweb.org/anthology/2020.coling-main.419)|Short / Long Text Classification, Coreference Resolution, Semantic Similarity, Keyword Recongition, NLI, Machine Reading Comprehension|[[paper]](https://www.aclweb.org/anthology/2020.coling-main.419)
|Danish ðŸ‡©ðŸ‡°|2024-05|[Towards a Danish Semantic Reasoning Benchmark](https://aclanthology.org/2024.lrec-main.1421/)|Inference, Entailment, Synonymy, Similarity, Relatedness, Word Sense Disambiguation (WiC)	|[[paper]](https://aclanthology.org/2024.lrec-main.1421/)|
|Dutch ðŸ‡³ðŸ‡±|2023-12|[DUMB: A Benchmark for Smart Evaluation of Dutch Models](https://aclanthology.org/2023.emnlp-main.447/)|POS Tagging, NER, Word Sense Disambiguation, Pronoun Resolution, Causal Reasoning, NLI, Sentiment Analysis, Document Classification, Question Answering|[[paper]](https://aclanthology.org/2023.emnlp-main.447/)|
|Finnish ðŸ‡«ðŸ‡®|2020-10|[Towards Fully Bilingual Deep Language Modeling](https://arxiv.org/abs/2010.11639)|POS Tagging, NER, Dependency Parsing, Document Classification|[[paper]](https://arxiv.org/abs/2010.11639)|
|German ðŸ‡©ðŸ‡ª|2024-06|[SuperGLEBer: German Language Understanding Evaluation Benchmark](https://aclanthology.org/2024.naacl-long.438/)|NER, Document Classification, STS, QA|[[paper]](https://aclanthology.org/2024.naacl-long.438/)|
|Hungarian ðŸ‡­ðŸ‡º|2024-05|[HuLU: Hungarian Language Understanding Benchmark Kit](https://aclanthology.org/2024.lrec-main.733)|CoPA, RTE, SST, WNLI, CommitmentBank, ReCoRD QA|[[paper]](https://aclanthology.org/2024.lrec-main.733)|
|Italian ðŸ‡®ðŸ‡¹|2023-07|[UINAUIL: A Unified Benchmark for Italian Natural Language Understanding](https://aclanthology.org/2023.acl-demo.33)|Textual Entailment, Event Detection & Classification (EVENTI), Factuality Classification (FactA), Sentiment Analysis (SENTIPOLC), Irony Detection (IronITA), Hate Speech Detection (HaSpeeDe)	|[[paper]](https://aclanthology.org/2023.acl-demo.33)|
|Italian ðŸ‡®ðŸ‡¹|2024-06|[The Invalsi Benchmarks: Measuring Linguistic and Mathematical Understanding of Large Language Models in Italian](https://arxiv.org/abs/2406.17535)|Locate and Identify Information, Reconstruct Meaning, Reflect on Content/Form, Word Formation, Lexicon and Semantics, Morphology, Spelling, Syntax, Textuality and Pragmatics, Cloze (Fill-in-the-Blank), Multiple Choice (MC), Multiple Complex Choice (MCC), Unique Response (RU), Short Response (RB)|[[paper]](https://arxiv.org/abs/2406.17535)|
|Korean ðŸ‡°ðŸ‡·|2024-06|[KMMLU: Measuring Massive Multitask Language Understanding in Korean](https://arxiv.org/abs/2402.11548)|Multichoice QA across 45 subjects, including STEM, Humanities, Applied Sciences|[[paper]](https://arxiv.org/abs/2402.11548)|
|Norwegian ðŸ‡³ðŸ‡´|2023-05|[NorBench -- A Benchmark for Norwegian Language Models](https://arxiv.org/abs/2305.03880)|Morpho-syntactic tasks (POS Tagging, Lemmatization, Dependency Parsing), NER, Sentiment Analysis (Document-level, Sentence-level, Targeted), Linguistic Acceptability, Question Answering, Machine Translation, Diagnostics of Harmful Predictions (Gender Bias, Harmfulness)|[[paper]](https://arxiv.org/abs/2305.03880) [[code]](https://github.com/ltgoslo/norbench)|
|Polish ðŸ‡µðŸ‡±|2020-05|[KLEJ: Comprehensive Benchmark for Polish Language Understanding](https://arxiv.org/abs/2005.00630)|NER, Sentence Relatedness, Textual Entailment, Cyberbullying Detection, Sentiment Analysis (In-Domain & Out-of-Domain), Question Answering, Paraphrase Detection, Sentiment Analysis (Allegro Reviews)|[[paper]](https://arxiv.org/abs/2005.00630)|
|Polish ðŸ‡µðŸ‡±|2022-12|[This is the way: Designing and Compiling LEPISZCZE, a Comprehensive NLP Benchmark for Polish](https://proceedings.neurips.cc/paper_files/paper/2022/file/890b206ebb79e550f3988cb8db936f42-Paper-Datasets_and_Benchmarks.pdf)|Sentiment Analysis, Abusive Clauses Detection, Political Advertising Detection, NLI, NER, POS Tagging, Paraphrase Classification, Punctuation Restoration, Dialogue Acts Classification	|[[paper]](https://proceedings.neurips.cc/paper_files/paper/2022/file/890b206ebb79e550f3988cb8db936f42-Paper-Datasets_and_Benchmarks.pdf)|
|Portuguese ðŸ‡µðŸ‡¹ðŸ‡§ðŸ‡·|2024-04|[PORTULAN ExtraGLUE Datasets and Models](https://arxiv.org/abs/2404.05333)|SST-2, MRPC, STS-B, MNLI, QNLI, RTE, WNLI, BoolQ, MultiRC, CoPA	|[[paper]](https://arxiv.org/abs/2404.05333)|
|Romanian ðŸ‡·ðŸ‡´|2021-12|[LiRo: Benchmark and Leaderboard for Romanian Language Tasks](https://openreview.net/pdf?id=JH61CD7afTv)|Document Classification, NER, Machine Translation, Sentiment Analysis, POS Tagging, Dependency Parsing, Language Modeling, QA, STS, Gender Debiasing|[[paper]](https://openreview.net/pdf?id=JH61CD7afTv) [[web]](https://lirobenchmark.github.io/)|
|Russian ðŸ‡·ðŸ‡º|2024-01|[MERA: A Comprehensive LLM Evaluation in Russian](https://arxiv.org/abs/2401.04531)|MathLogicQA, MultiQ, PARus, RCB, ruModAr, ruMultiAr, ruOpenBookQA, ruTiE, ruWorldTree, RWSD, SimpleAr, BPS, CheGeKa, LCS, ruHumanEval, ruMMLU, USE, ruDetox, ruEthics, ruHateSpeech, ruHHH|[[paper]](https://arxiv.org/abs/2401.04531) [[web]](https://mera.a-ai.ru/en)|
|Slovenian ðŸ‡¸ðŸ‡®|2022-02|[Slovene SuperGLUE Benchmark: Translation and Evaluation](https://arxiv.org/abs/2202.04994)|BoolQ, CB, COPA, MultiRC, RTE, WSC|[[paper]](https://arxiv.org/abs/2202.04994)|
|Swedish ðŸ‡¸ðŸ‡ª|2023-12|[Superlim: A Swedish Language Understanding Evaluation Benchmark](https://aclanthology.org/2023.emnlp-main.506/)|Absabank-Imm, Argumentation Sentences, DaLAJ-GED, SweParaphrase, SweDN, SweFAQ, SweNLI, SweWiC, SweWinograd, SuperSim, Swedish Analogy, SweSAT, SweDiagnostics, SweWinogender	|[[paper]](https://aclanthology.org/2023.emnlp-main.506/)|
